\section*{Introduction}

Semantic segmentation is the task of assigning each pixel in an image a specified label. A single image can be partitioned into multiple meaningful segments corresponding to a given object or region of interest. Labels are assigned to individual pixels, marking boundaries and shapes. Altogether, this task has many applications in computer vision including but not limited to autonomous driving, video surveillance, and object recognition.

In recent years, convolutional neural networks (CNNs) have proven to be an effective approach to semantic segmentation. Such models learn hierarchical features by capturing information using convolutional blocks. Convolutions and related techniques such as weight initialization, batch normalization, and pooling help avoid the flat, dense layers of a traditional fully connected neural network allowing for less computation and improved feature maps.

\subsection*{Xavier Weight Initialization}
In our architecture, we use Xavier weight initialization. In Uniform Xavier Initialization, a layer’s weights are chosen from a random uniform distribution bounded between

\begin{equation}
	\pm \displaystyle\frac{\sqrt{6}}{\sqrt{n_i + n_{i + 1}}}
\end{equation}

where $n_i$ is the number of incoming network connections and $n_{i + 1}$ is the number of outgoing network connections.

In Normal Xavier Initialization, a layer’s weights are chosen from a normal distribution with

\begin{equation}
	\sigma = \displaystyle\frac{\sqrt{2}}{\sqrt{n_i + n_{i + 1}}}
\end{equation}

where $n_i$ is the number of incoming network connections and $n_{i + 1}$ is the number of outgoing network connections.

The Xavier initialization was created in response to the problem of vanishing and exploding gradients in deep neural networks in the context of symmetric nonlinearities (sigmoid, tanh). The intuition is that the weights should not be intialized randomly, but rather proportional to the size of two connected layers. As a result, the variance of activations and gradients would be maintained through the layers of a deep network.

\subsection*{Kaiming Weight Initialization}
With the rise of ReLU, the nonlinearity can no longer be assumed to be symmetric. As such, the assumptions made by the Xavier Weight Initialization fall apart. In 2015, He et. al demonstrated that a ReLU layer typically has a standard deviation close to

\begin{equation}
	\sqrt{\displaystyle\frac{n_{i}}{2}}
\end{equation}

where $n_i$ is the number of incoming network connections. As such, weights initially chosen from a normal distribution should be weighted by $\sqrt{\frac{n_{i}}{2}}$, with bias tensors initalized to zero.

\subsection*{Batch Normalization}
During the training of a neural network, at each layer, inputs (activations) change as the parameters of the previous layers get updated. Batch normalization normalizes the activations of each layer by subtracting the mean and dividing by the standard deviation of the activations within a mini-batch. We implement batch normalization using PyTorch's \texttt{nn} module implementation. For example, we define a layer used for batch normalization as

\begin{center}
	\texttt{self.bnd1 = nn.BatchNorm2d(32)}
\end{center}

This ensures that the inputs to each layer have a consistent distribution, which helps in stabilizing the training process.

\subsection*{Pixel Accuracy}
Pixel accuracy is a straightforward evaluation metric commonly used in image classification tasks to measure the percentage of correctly classified pixels in an image. It provides a simple measure of overall accuracy without considering class imbalance.

Pixel accuracy is calculated as:
\begin{equation}
	\text{Pixel Accuracy} = \frac{\text{Number of Correctly Classified Pixels}}{\text{Total Number of Pixels}}
\end{equation}

Where:
\begin{itemize}
	\item Number of Correctly Classified Pixels: The count of pixels for which the predicted class matches the ground truth class.
	\item Total Number of Pixels: The total count of pixels in the image.
\end{itemize}

While pixel accuracy provides a quick measure of overall performance, it may not be the most informative metric for tasks with class imbalance or when individual classes are of interest.

\subsection*{Intersection over Union (IoU)}
Intersection over Union (IoU), also known as the Jaccard index, is a popular evaluation metric in semantic segmentation tasks. It measures the overlap between the predicted segmentation mask and the ground truth mask for each class. IoU provides a more nuanced understanding of model performance by considering both true positives and false positives.

For a given class $c$, IoU is calculated as:
\begin{equation}
	IoU_c = \frac{\text{Area of Intersection between predicted and ground truth mask for class } c}{\text{Area of Union between predicted and ground truth mask for class } c}
\end{equation}

The overall IoU for all classes is often computed as the mean or weighted mean of individual class IoU scores:
\begin{equation}
	IoU = \frac{1}{N} \sum_{c=1}^{N} IoU_c
\end{equation}

Where:
\begin{itemize}
	\item $N$ is the total number of classes.
	\item $IoU_c$ is the IoU score for class $c$.
\end{itemize}

IoU ranges from 0 to 1, with higher values indicating better segmentation accuracy. A value of 1 indicates perfect overlap between the predicted and ground truth masks, while a value of 0 indicates no overlap.

IoU is particularly useful for tasks where precise localization and segmentation accuracy are essential, such as medical image analysis, object detection, and scene understanding. It provides insights into how well the model captures the spatial extent of different classes within the image.
